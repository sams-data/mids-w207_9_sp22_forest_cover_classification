{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to write cleaned datasets\n",
    "\n",
    "### Creates the following csvs\n",
    "\n",
    "1. `train_df.csv` = initial train csv with a new column that maps integer class labels to a character description\n",
    "2. `dev_data.csv` = random 10% subset of initial train feature data. This excludes the Y value so only includes features\n",
    "3. `dev_labels.csv` = random 10% subset of initial train feature data. This only includes the Y value\n",
    "4. `train_data.csv` = random 90% subset of initial train feature data. This excludes the Y value so only includes features\n",
    "5. `train_labels.csv` = random 90% subset of initial train feature data. This only includes the Y value\n",
    "\n",
    "Goal of this is to standardize data sets each group member uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and build modeling datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data shape:  (13608, 55)\n",
      "Train Labels shape:  (13608,)\n",
      "\n",
      "Dev Data shape:  (1512, 55)\n",
      "Dev Labels shape:  (1512,)\n",
      "\n",
      "Test Data shape:  (565892, 55)\n",
      "\n",
      "Dev split check status: True\n"
     ]
    }
   ],
   "source": [
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# load data\n",
    "\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "# ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "# set up modeling datasets\n",
    "\n",
    "# X = all but last column \n",
    "X_train = np.array(train.iloc[:,:-1])\n",
    "X_test = np.array(test)\n",
    "\n",
    "# Y = last column only\n",
    "Y_train = np.array(train.iloc[:,-1].tolist())\n",
    "\n",
    "# build dev set based on random subset (10% of train data)\n",
    "shuffle = np.random.permutation(np.arange(X_train.shape[0]))\n",
    "X_train, Y_train = X_train[shuffle], Y_train[shuffle]\n",
    "\n",
    "dev_size = round(X_train.shape[0] * 0.1)\n",
    "dev_data, dev_labels = X_train[:dev_size], Y_train[:dev_size]\n",
    "train_data, train_labels = X_train[dev_size:], Y_train[dev_size:]\n",
    "test_data = X_test\n",
    "\n",
    "print('Train Data shape: ', train_data.shape)\n",
    "print('Train Labels shape: ', train_labels.shape)\n",
    "print()\n",
    "print('Dev Data shape: ', dev_data.shape)\n",
    "print('Dev Labels shape: ', dev_labels.shape)\n",
    "print()\n",
    "print('Test Data shape: ', test_data.shape)\n",
    "print()\n",
    "\n",
    "# check dev split works\n",
    "print(f'Dev split check status: {dev_data.shape[0] + train_data.shape[0] == X_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label categories columns\n",
    "\n",
    "The cover types (Y) include;\n",
    "1. Spruce/Fir\n",
    "2. Lodgepole Pine\n",
    "3. Ponderosa Pine\n",
    "4. Cottonwood/Willow\n",
    "5. Aspen\n",
    "6. Douglas-fir\n",
    "7. Krummholz\n",
    "\n",
    "Merge this with the train df for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_categories = ['Spruce/Fir', \n",
    "                    'Lodgepole Pine', \n",
    "                    'Ponderosa Pine', \n",
    "                    'Cottonwood/Willow', \n",
    "                    'Aspen',\n",
    "                    'Douglas-fir',\n",
    "                    'Krummholz']\n",
    "label_categories = pd.DataFrame(data = zip(label_categories,list(range(1,8,1))), columns = ['Cover_Type_Name','Cover_Type'])\n",
    "train = train.merge(label_categories, left_on='Cover_Type', right_on='Cover_Type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write new datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train_df.csv')\n",
    "pd.DataFrame(dev_data).to_csv('data/dev_data.csv')\n",
    "pd.DataFrame(dev_labels).to_csv('data/dev_labels.csv')\n",
    "pd.DataFrame(train_data).to_csv('data/train_data.csv')\n",
    "pd.DataFrame(train_labels).to_csv('data/train_labels.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
