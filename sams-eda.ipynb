{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import theano \n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "print(theano.config.device) # We're using CPUs (for now)\n",
    "print(theano.config.floatX) # Should be 64 bit for CPUs\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev size: 3024\n",
      "Train size: 12096\n",
      "Features: 56\n",
      "Classes: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7527.118800</td>\n",
       "      <td>2751.081267</td>\n",
       "      <td>156.782821</td>\n",
       "      <td>16.483052</td>\n",
       "      <td>228.625165</td>\n",
       "      <td>51.281581</td>\n",
       "      <td>1707.330357</td>\n",
       "      <td>212.861690</td>\n",
       "      <td>218.987186</td>\n",
       "      <td>134.955936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045883</td>\n",
       "      <td>0.040179</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.006614</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.050761</td>\n",
       "      <td>0.043320</td>\n",
       "      <td>0.029266</td>\n",
       "      <td>3.994213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4362.528179</td>\n",
       "      <td>416.896151</td>\n",
       "      <td>110.093786</td>\n",
       "      <td>8.443301</td>\n",
       "      <td>211.421953</td>\n",
       "      <td>61.433674</td>\n",
       "      <td>1319.372015</td>\n",
       "      <td>30.392477</td>\n",
       "      <td>22.776599</td>\n",
       "      <td>45.787111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209240</td>\n",
       "      <td>0.196386</td>\n",
       "      <td>0.039603</td>\n",
       "      <td>0.081059</td>\n",
       "      <td>0.025710</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.219517</td>\n",
       "      <td>0.203585</td>\n",
       "      <td>0.168558</td>\n",
       "      <td>2.000074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1863.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-146.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3734.500000</td>\n",
       "      <td>2378.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>755.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7513.500000</td>\n",
       "      <td>2753.500000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1310.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11283.250000</td>\n",
       "      <td>3105.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>2263.250000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15119.000000</td>\n",
       "      <td>3849.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1318.000000</td>\n",
       "      <td>554.000000</td>\n",
       "      <td>6836.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean    7527.118800   2751.081267    156.782821     16.483052    228.625165   \n",
       "std     4362.528179    416.896151    110.093786      8.443301    211.421953   \n",
       "min        1.000000   1863.000000      0.000000      0.000000      0.000000   \n",
       "25%     3734.500000   2378.000000     65.000000     10.000000     67.000000   \n",
       "50%     7513.500000   2753.500000    126.000000     15.000000    180.000000   \n",
       "75%    11283.250000   3105.000000    261.000000     22.000000    330.000000   \n",
       "max    15119.000000   3849.000000    360.000000     50.000000   1318.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean      51.281581   1707.330357    212.861690    218.987186    134.955936   \n",
       "std       61.433674   1319.372015     30.392477     22.776599     45.787111   \n",
       "min     -146.000000      0.000000     58.000000     99.000000      0.000000   \n",
       "25%        5.000000    755.000000    196.000000    207.000000    106.000000   \n",
       "50%       33.000000   1310.000000    220.000000    223.000000    138.000000   \n",
       "75%       79.000000   2263.250000    235.000000    235.000000    167.000000   \n",
       "max      554.000000   6836.000000    254.000000    254.000000    248.000000   \n",
       "\n",
       "       ...            46            47            48            49  \\\n",
       "count  ...  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean   ...      0.045883      0.040179      0.001571      0.006614   \n",
       "std    ...      0.209240      0.196386      0.039603      0.081059   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 50            51            52            53            54  \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean       0.000661      0.001984      0.050761      0.043320      0.029266   \n",
       "std        0.025710      0.044501      0.219517      0.203585      0.168558   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                 55  \n",
       "count  12096.000000  \n",
       "mean       3.994213  \n",
       "std        2.000074  \n",
       "min        1.000000  \n",
       "25%        2.000000  \n",
       "50%        4.000000  \n",
       "75%        6.000000  \n",
       "max        7.000000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "X = np.array(train)\n",
    "Y = np.array(np.array(train[\"Cover_Type\"].tolist()))\n",
    "n = X.shape[0]\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(n))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "percent_in_dev = .2\n",
    "dev_slice = int(percent_in_dev * n)\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "dev_dat, dev_lab = X[:dev_slice], Y[:dev_slice]\n",
    "train_dat, train_lab = X[dev_slice:], Y[dev_slice:]\n",
    "# train_df = train.iloc[shuffle,:].iloc[dev_slice: , :]\n",
    "\n",
    "n_dev = dev_dat.shape[0]\n",
    "n_train = train_dat.shape[0]\n",
    "n_feat = train_dat.shape[1]\n",
    "\n",
    "def binarizeY(data):\n",
    "    binarized_data = np.zeros((data.size,10))\n",
    "    for j in range(0,data.size):\n",
    "        feature = data[j:j+1]\n",
    "        i = feature.astype(np.int64) \n",
    "        binarized_data[j,i]=1\n",
    "    return binarized_data\n",
    "\n",
    "train_lab_b = binarizeY(train_lab)\n",
    "dev_lab_b = binarizeY(dev_labels)\n",
    "n_class = train_lab_b[1].size\n",
    "\n",
    "print(f'Dev size: {n_dev}')\n",
    "print(f'Train size: {n_train}')\n",
    "print(f'Features: {n_feat}')\n",
    "print(f'Classes: {n_class}')\n",
    "pd.DataFrame(train_dat).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "      <td>12096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.007867</td>\n",
       "      <td>0.008990</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>0.008093</td>\n",
       "      <td>0.006676</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.007195</td>\n",
       "      <td>0.009001</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.008130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.001362</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.006980</td>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008882</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>0.009063</td>\n",
       "      <td>0.009090</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>0.008859</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.008959</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.006088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.008288</td>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.006763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.007853</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.005980</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.005520</td>\n",
       "      <td>0.009303</td>\n",
       "      <td>0.009209</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>0.012388</td>\n",
       "      <td>0.010801</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.009537</td>\n",
       "      <td>0.009937</td>\n",
       "      <td>0.009705</td>\n",
       "      <td>0.010655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.015801</td>\n",
       "      <td>0.012577</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>0.024548</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>0.062947</td>\n",
       "      <td>0.028807</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042448</td>\n",
       "      <td>0.045361</td>\n",
       "      <td>0.229416</td>\n",
       "      <td>0.111803</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>0.053149</td>\n",
       "      <td>0.014248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean       0.007867      0.008990      0.007441      0.008093      0.006676   \n",
       "std        0.004559      0.001362      0.005225      0.004145      0.006173   \n",
       "min        0.000001      0.006088      0.000000      0.000000      0.000000   \n",
       "25%        0.003903      0.007771      0.003085      0.004910      0.001956   \n",
       "50%        0.007853      0.008998      0.005980      0.007364      0.005256   \n",
       "75%        0.011792      0.010146      0.012388      0.010801      0.009636   \n",
       "max        0.015801      0.012577      0.017086      0.024548      0.038485   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean       0.005827      0.007195      0.009001      0.009044      0.008610   \n",
       "std        0.006980      0.005560      0.001285      0.000941      0.002921   \n",
       "min       -0.016589      0.000000      0.002453      0.004088      0.000000   \n",
       "25%        0.000568      0.003182      0.008288      0.008549      0.006763   \n",
       "50%        0.003750      0.005520      0.009303      0.009209      0.008805   \n",
       "75%        0.008976      0.009537      0.009937      0.009705      0.010655   \n",
       "max        0.062947      0.028807      0.010741      0.010490      0.015823   \n",
       "\n",
       "       ...            46            47            48            49  \\\n",
       "count  ...  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean   ...      0.001948      0.001823      0.000360      0.000739   \n",
       "std    ...      0.008882      0.008908      0.009086      0.009063   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      0.042448      0.045361      0.229416      0.111803   \n",
       "\n",
       "                 50            51            52            53            54  \\\n",
       "count  12096.000000  12096.000000  12096.000000  12096.000000  12096.000000   \n",
       "mean       0.000234      0.000405      0.002049      0.001892      0.001555   \n",
       "std        0.009090      0.009084      0.008859      0.008894      0.008959   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.353553      0.204124      0.040357      0.043685      0.053149   \n",
       "\n",
       "                 55  \n",
       "count  12096.000000  \n",
       "mean       0.008130  \n",
       "std        0.004071  \n",
       "min        0.002035  \n",
       "25%        0.004071  \n",
       "50%        0.008142  \n",
       "75%        0.012213  \n",
       "max        0.014248  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## normalize training and dev\n",
    "# pd.DataFrame(train_dat).head()\n",
    "\n",
    "train_dat = normalize(train_dat, axis=0)\n",
    "dev_dat = normalize(dev_dat, axis=0)\n",
    "pd.DataFrame(train_dat).describe()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 accuracy = 0.13062169\n",
      "2 accuracy = 0.13095238\n",
      "3 accuracy = 0.13128307\n",
      "4 accuracy = 0.13194444\n",
      "5 accuracy = 0.13161376\n",
      "6 accuracy = 0.13194444\n",
      "7 accuracy = 0.13227513\n",
      "8 accuracy = 0.13293651\n",
      "9 accuracy = 0.13326720\n",
      "10 accuracy = 0.13359788\n",
      "train time = 73.96501970291138\n",
      "predict time = 0.00\n"
     ]
    }
   ],
   "source": [
    "## (1) Parameters\n",
    "n_hidden_nodes = 50 \n",
    "w_1 = theano.shared(np.asarray((np.random.randn(*(n_feat, n_hidden_nodes))*.01)))\n",
    "w_2 = theano.shared(np.asarray((np.random.randn(*(n_hidden_nodes, n_hidden_nodes))*.01)))\n",
    "w_3 = theano.shared(np.asarray((np.random.randn(*(n_hidden_nodes, n_hidden_nodes))*.01)))\n",
    "w_4 = theano.shared(np.asarray((np.random.randn(*(n_hidden_nodes, n_class))*.01)))\n",
    "params = [w_1, w_2, w_3]\n",
    "\n",
    "\n",
    "## (2) Model\n",
    "X = T.matrix()\n",
    "Y = T.matrix()\n",
    "# Two notes:\n",
    "# First, feed forward is the composition of layers (dot product + activation function)\n",
    "# Second, activation on the hidden layer still uses sigmoid\n",
    "srng = RandomStreams()\n",
    "def dropout(X, p=0.):\n",
    "    if p > 0:\n",
    "        X *= srng.binomial(X.shape, p=1 - p)\n",
    "        X /= 1 - p\n",
    "    return X\n",
    "\n",
    "def model(X, w_1, w_2, w_3, w_4, p=0):\n",
    "    rectifier = lambda first_layer, second_layer : T.nnet.relu(T.dot(dropout(first_layer,p), second_layer))\n",
    "    X_w_1 = rectifier(X, w_1)\n",
    "    w_1_2 = rectifier(X_w_1, w_2)\n",
    "    w_2_3 = rectifier(w_1_2, w_3)\n",
    "    w_3_4 = rectifier(w_2_3, w_4)\n",
    "    return T.nnet.softmax(w_3_4)\n",
    "y_hat = model(X, w_1, w_2, w_3, w_4)\n",
    "\n",
    "\n",
    "## (3) Cost...same as logistic regression\n",
    "cost = T.mean(T.nnet.categorical_crossentropy(y_hat, Y))\n",
    "\n",
    "\n",
    "## (4) Minimization.  Update rule changes to backpropagation.\n",
    "alpha = 0.01\n",
    "def backprop(cost, w):\n",
    "    grads = T.grad(cost=cost, wrt=w)\n",
    "    updates = []\n",
    "    for w1, grad in zip(w, grads):\n",
    "        updates.append([w1, w1 - grad * alpha])\n",
    "    return updates\n",
    "update = backprop(cost, params)\n",
    "train = theano.function(inputs=[X, Y], outputs=cost, updates=update, allow_input_downcast=True)\n",
    "y_pred = T.argmax(y_hat, axis=1)\n",
    "predict = theano.function(inputs=[X], outputs=y_pred, allow_input_downcast=True)\n",
    "\n",
    "miniBatchSize = 1\n",
    "def gradientDescentStochastic(epochs):\n",
    "    trainTime = 0.0\n",
    "    predictTime = 0.0\n",
    "    start_time = time.time()\n",
    "    acc = [0]\n",
    "    for i in range(epochs):\n",
    "        for start, end in zip(range(0, n_train, miniBatchSize), range(miniBatchSize, n_train, miniBatchSize)):\n",
    "            cost = train(train_dat[start:end], train_lab_b[start:end])\n",
    "        trainTime =  trainTime + (time.time() - start_time)\n",
    "        acc.append(np.mean(np.argmax(dev_lab_b, axis=1) == predict(dev_dat)))\n",
    "        print(f'{i+1} accuracy = {acc[i+1]:.8f}')\n",
    "    print(f'train time = {trainTime}')\n",
    "\n",
    "gradientDescentStochastic(10)\n",
    "\n",
    "start_time = time.time()\n",
    "predict(dev_dat)   \n",
    "print('predict time = %.2f' %(time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e154723739a62da1ddbb97cffcb1928f4621ae866510e1af6fff45adbf967f5"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
